{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ffc77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet torch-lucent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ef695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import torch\n",
    "\n",
    "from lucent.optvis import render, param, transform, objectives\n",
    "from lucent.misc.io import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66503d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62321e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class KittyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0 = nn.BatchNorm2d(3)\n",
    "        self.conv1 = nn.Conv2d(3, 9, 3)\n",
    "        self.pool1 = nn.AvgPool2d(4, 4)\n",
    "        \n",
    "        self.conv1_bn = nn.BatchNorm2d(9)\n",
    "        self.conv2 = nn.Conv2d(9, 16, 3)\n",
    "        self.pool2 = nn.AvgPool2d(4, 4)\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 25, 3)\n",
    "        self.pool3 = nn.AvgPool2d(4, 4)\n",
    "        \n",
    "        self.conv3_bn = nn.BatchNorm2d(25)\n",
    "        self.conv4 = nn.Conv2d(25, 36, 3)\n",
    "        self.pool4 = nn.AvgPool2d(2 , 2)\n",
    "        \n",
    "        self.fc = nn.Linear(324, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.conv1_bn(self.pool1(F.relu(self.conv1(x))))\n",
    "        x = self.conv2_bn(self.pool2(F.relu(self.conv2(x))))\n",
    "        x = self.conv3_bn(self.pool3(F.relu(self.conv3(x))))\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class LongcatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.conv1 = nn.Conv2d(3, 9, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm2d(9)\n",
    "        self.conv2 = nn.Conv2d(9, 16, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3_bn = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 25, 3)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv4_bn = nn.BatchNorm2d(25)\n",
    "        self.conv4 = nn.Conv2d(25, 36, 3)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv5_bn = nn.BatchNorm2d(36)\n",
    "        self.conv5 = nn.Conv2d(36, 36, 3)\n",
    "  \n",
    "        self.conv6_bn = nn.BatchNorm2d(36)\n",
    "        self.conv6 = nn.Conv2d(36, 49, 3)\n",
    "\n",
    "        self.conv7_bn = nn.BatchNorm2d(49)\n",
    "        self.conv7 = nn.Conv2d(49, 49, 3)\n",
    "        \n",
    "        self.conv8_bn = nn.BatchNorm2d(49)\n",
    "        self.conv8 = nn.Conv2d(49, 49, 3)\n",
    "        \n",
    "        self.conv9_bn = nn.BatchNorm2d(49)\n",
    "        self.conv9 = nn.Conv2d(49, 49, 3)\n",
    "        self.pool9 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv10_bn = nn.BatchNorm2d(49)\n",
    "        self.conv10 = nn.Conv2d(49, 49, 3)\n",
    "        self.pool10 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc = nn.Linear(1764, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2_bn(self.pool1(F.relu(self.conv1(x))))\n",
    "        x = self.conv3_bn(self.pool2(F.relu(self.conv2(x))))\n",
    "        x = self.conv4_bn(self.pool3(F.relu(self.conv3(x))))\n",
    "        x = self.conv5_bn(self.pool4(F.relu(self.conv4(x))))\n",
    "\n",
    "        x = self.conv6_bn(F.relu(self.conv5(x)))  \n",
    "        x = self.conv7_bn(F.relu(self.conv6(x)))\n",
    "        x = self.conv8_bn(F.relu(self.conv7(x)))\n",
    "        x = self.conv9_bn(F.relu(self.conv8(x)))\n",
    "        \n",
    "        \n",
    "        x = self.conv10_bn(self.pool9(F.relu(self.conv9(x))))\n",
    "        x = self.pool10(F.relu(self.conv10(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a42fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@objectives.wrap_objective()\n",
    "def dot_compare(layer, batch=1, cossim_pow=0):\n",
    "    def inner(T):\n",
    "        dot = (T(layer)[batch] * T(layer)[0]).sum()\n",
    "        mag = torch.sqrt(torch.sum(T(layer)[0]**2))\n",
    "        cossim = dot/(1e-6 + mag)\n",
    "        return -dot * cossim ** cossim_pow\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85122a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feature_inversion(img, model, layer=None, n_steps=512, cossim_pow=0.0):\n",
    "    # Convert image to torch.tensor and scale image\n",
    "    img = torch.tensor(np.transpose(img, [2, 0, 1])).to(device)\n",
    "\n",
    "    obj = objectives.Objective.sum([\n",
    "    1.0 * dot_compare(layer, cossim_pow=cossim_pow),\n",
    "    objectives.blur_input_each_step(),\n",
    "    ])\n",
    "\n",
    "    # Initialize parameterized input and stack with target image\n",
    "    # to be accessed in the objective function\n",
    "    params, image_f = param.image(640)\n",
    "    def stacked_param_f():\n",
    "        return params, lambda: torch.stack([image_f()[0], img])\n",
    "\n",
    "    transforms = [\n",
    "    transform.pad(8, mode='constant', constant_value=.5),\n",
    "    transform.jitter(8),\n",
    "    transform.random_scale([0.9, 0.95, 1.05, 1.1] + [1]*4),\n",
    "    transform.random_rotate(list(range(-5, 5)) + [0]*5),\n",
    "    transform.jitter(2),\n",
    "    ]\n",
    "\n",
    "    _ = render.render_vis(model, obj, stacked_param_f, transforms=transforms, thresholds=(n_steps,), show_image=False, progress=False)\n",
    "\n",
    "    show(_[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b217be",
   "metadata": {},
   "source": [
    "## Kitty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739854f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kitty = KittyNet()\n",
    "kitty.load_state_dict(torch.load('saved_models/kitty/epoch_7_batch_5000.pth', map_location=device))\n",
    "kitty.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fef72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kitty_layers = [f'conv{i}' for i in range(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d6409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open(\"dataset/test/Amsterdam/0000093_0002505_0000002_0000780.jpg\"), np.float32)\n",
    "img = img/255\n",
    "\n",
    "layers = [f'conv{i}' for i in range(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa43e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for layer in kitty_layers:\n",
    "    print(layer)\n",
    "    feature_inversion(img, kitty, layer=layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d8aac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open(\"dataset/test/LasVegas/0000075_0018745_0000004_0002564.jpg\"), np.float32)\n",
    "\n",
    "layers = [f'conv{i}' for i in range(1, 5)]\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "    feature_inversion(img, layer=layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083f3ec",
   "metadata": {},
   "source": [
    "## Longcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1879063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "longcat = LongcatNet()\n",
    "longcat.load_state_dict(torch.load('saved_models/longcat/epoch_7_batch_5000.pth', map_location=device))\n",
    "longcat.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c89543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "longcat_layer = [f'conv{i}' for i in range(1,11)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6c072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open(\"dataset/test/LasVegas/0000075_0018745_0000004_0002564.jpg\"), np.float32)\n",
    "img = img/255\n",
    "\n",
    "for layer in longcat_layer:\n",
    "    print(layer)\n",
    "    feature_inversion(img, longcat, layer=layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee72255",
   "metadata": {},
   "source": [
    "## Inception, pretrainedâ€”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adac5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lucent.modelzoo import inceptionv1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = inceptionv1(pretrained=True)\n",
    "_ = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63670de",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['conv2d%d' % i for i in range(0, 3)] + \\\n",
    "         ['mixed3a', 'mixed3b', 'mixed4a',\n",
    "          'mixed4b', 'mixed4c', 'mixed4d',\n",
    "          'mixed4e', 'mixed5a', 'mixed5b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layers:\n",
    "    print(layer)\n",
    "    feature_inversion(img, model, layer=layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b91fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
