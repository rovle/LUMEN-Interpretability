{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c59cb773",
   "metadata": {},
   "source": [
    "## Metode _atribucije_ u Captumu\n",
    "\n",
    "Isprobavamo paket Captum i njegove metode atribucije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd6757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall --quiet captum\n",
    "!pip install --quiet captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bda82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc8421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c50c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='dataset/train', transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(root='dataset/test', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=8, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "classes = ('Amsterdam', 'Firenca', 'LasVegas', 'NYC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc622f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LongcatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.conv1 = nn.Conv2d(3, 9, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm2d(9)\n",
    "        self.conv2 = nn.Conv2d(9, 16, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3_bn = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 25, 3)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv4_bn = nn.BatchNorm2d(25)\n",
    "        self.conv4 = nn.Conv2d(25, 36, 3)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv5_bn = nn.BatchNorm2d(36)\n",
    "        self.conv5 = nn.Conv2d(36, 36, 3)\n",
    "  \n",
    "        self.conv6_bn = nn.BatchNorm2d(36)\n",
    "        self.conv6 = nn.Conv2d(36, 49, 3)\n",
    "\n",
    "        self.conv7_bn = nn.BatchNorm2d(49)\n",
    "        self.conv7 = nn.Conv2d(49, 49, 3)\n",
    "        \n",
    "        self.conv8_bn = nn.BatchNorm2d(49)\n",
    "        self.conv8 = nn.Conv2d(49, 49, 3)\n",
    "        \n",
    "        self.conv9_bn = nn.BatchNorm2d(49)\n",
    "        self.conv9 = nn.Conv2d(49, 49, 3)\n",
    "        self.pool9 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv10_bn = nn.BatchNorm2d(49)\n",
    "        self.conv10 = nn.Conv2d(49, 49, 3)\n",
    "        self.pool10 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc = nn.Linear(1764, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2_bn(self.pool1(F.relu(self.conv1(x))))\n",
    "        x = self.conv3_bn(self.pool2(F.relu(self.conv2(x))))\n",
    "        x = self.conv4_bn(self.pool3(F.relu(self.conv3(x))))\n",
    "        x = self.conv5_bn(self.pool4(F.relu(self.conv4(x))))\n",
    "\n",
    "        x = self.conv6_bn(F.relu(self.conv5(x)))  \n",
    "        x = self.conv7_bn(F.relu(self.conv6(x)))\n",
    "        x = self.conv8_bn(F.relu(self.conv7(x)))\n",
    "        x = self.conv9_bn(F.relu(self.conv8(x)))\n",
    "        \n",
    "        \n",
    "        x = self.conv10_bn(self.pool9(F.relu(self.conv9(x))))\n",
    "        x = self.pool10(F.relu(self.conv10(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "longcat = LongcatNet()\n",
    "longcat = longcat.to(device)\n",
    "\n",
    "longcat.load_state_dict(torch.load('saved_models/longcat/epoch_7_batch_5000.pth', map_location=device))\n",
    "longcat.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0d058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def imshow(img, transpose = True):\n",
    "    npimg = img.numpy()\n",
    "    fig, ax = subplots(figsize=((22, 8)))\n",
    "    tight_layout()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
    "\n",
    "\n",
    "outputs = longcat(images.cuda())\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01bd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "imgg = Image.open(test_loader.dataset.samples[55][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e94701",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread(test_loader.dataset.samples[55][0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa2133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ind = 0\n",
    "\n",
    "input = images[ind].unsqueeze(0)\n",
    "input.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af0491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def attribute_image_features(algorithm, input, **kwargs):\n",
    "    longcat.zero_grad()\n",
    "    tensor_attributions = algorithm.attribute(input,\n",
    "                                              target=labels[ind],\n",
    "                                              **kwargs\n",
    "                                             )\n",
    "    \n",
    "    return tensor_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409584b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saliency = Saliency(longcat)\n",
    "grads = saliency.attribute(input.cuda(), target=labels[ind].item())\n",
    "grads = np.transpose(grads.cpu().squeeze(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d807a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(longcat)\n",
    "attr_ig, delta = attribute_image_features(ig, input.cuda(), baselines=input.cuda() * 0, return_convergence_delta=True)\n",
    "attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "print('Approximation delta: ', abs(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b808669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(longcat)\n",
    "nt = NoiseTunnel(ig)\n",
    "attr_ig_nt = attribute_image_features(nt, input.cuda(), baselines=input.cuda() * 0, nt_type='smoothgrad_sq',\n",
    "                                      n_samples=4, stdevs=0.2)\n",
    "attr_ig_nt = np.transpose(attr_ig_nt.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191afa93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = DeepLift(longcat)\n",
    "attr_dl = attribute_image_features(dl, input.cuda(), baselines=input.cuda() * 0)\n",
    "attr_dl = np.transpose(attr_dl.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497d4e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Original Image')\n",
    "print('Predicted:', classes[predicted[ind]], \n",
    "      ' Probability:', torch.max(F.softmax(outputs, 1)).item())\n",
    "\n",
    "original_image = np.transpose((images[ind].cpu().detach().numpy()), (1, 2, 0))\n",
    "\n",
    "_ = viz.visualize_image_attr(None, original_image, \n",
    "                      method=\"original_image\", title=\"Original Image\")\n",
    "\n",
    "_ = viz.visualize_image_attr(grads.numpy(), original_image, method=\"blended_heat_map\", sign=\"absolute_value\",\n",
    "                          show_colorbar=True, title=\"Overlayed Gradient Magnitudes\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_ig, original_image, method=\"blended_heat_map\",sign=\"all\",\n",
    "                          show_colorbar=True, title=\"Overlayed Integrated Gradients\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_ig_nt, original_image, method=\"blended_heat_map\", sign=\"absolute_value\", \n",
    "                             outlier_perc=10, show_colorbar=True, \n",
    "                             title=\"Overlayed Integrated Gradients \\n with SmoothGrad Squared\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_dl, original_image, method=\"blended_heat_map\",sign=\"all\",show_colorbar=True, \n",
    "                          title=\"Overlayed DeepLift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50adb635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
