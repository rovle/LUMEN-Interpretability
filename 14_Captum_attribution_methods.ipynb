{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd6757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall --quiet captum\n",
    "!pip install --quiet captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bda82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc8421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b8c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c50c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='dataset/train', transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(root='dataset/test', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=4, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "classes = ('Amsterdam', 'Firenca', 'LasVegas', 'NYC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc622f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class KittyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0 = nn.BatchNorm2d(3)\n",
    "        self.conv1 = nn.Conv2d(3, 9, 3)\n",
    "        self.pool1 = nn.AvgPool2d(4, 4)\n",
    "        \n",
    "        self.conv1_bn = nn.BatchNorm2d(9)\n",
    "        self.conv2 = nn.Conv2d(9, 16, 3)\n",
    "        self.pool2 = nn.AvgPool2d(4, 4)\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 25, 3)\n",
    "        self.pool3 = nn.AvgPool2d(4, 4)\n",
    "        \n",
    "        self.conv3_bn = nn.BatchNorm2d(25)\n",
    "        self.conv4 = nn.Conv2d(25, 36, 3)\n",
    "        self.pool4 = nn.AvgPool2d(2 , 2)\n",
    "        \n",
    "        self.fc = nn.Linear(324, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.conv1_bn(self.pool1(F.relu(self.conv1(x))))\n",
    "        x = self.conv2_bn(self.pool2(F.relu(self.conv2(x))))\n",
    "        x = self.conv3_bn(self.pool3(F.relu(self.conv3(x))))\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918b2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kitty = KittyNet()\n",
    "kitty.load_state_dict(torch.load('saved_models/kitty/epoch_7_batch_5000.pth', map_location=device))\n",
    "kitty.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0d058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def imshow(img, transpose = True):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "\n",
    "outputs = kitty(images.cuda())\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa2133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = 2\n",
    "\n",
    "input = images[ind].unsqueeze(0)\n",
    "input.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af0491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def attribute_image_features(algorithm, input, **kwargs):\n",
    "    kitty.zero_grad()\n",
    "    tensor_attributions = algorithm.attribute(input,\n",
    "                                              target=labels[ind],\n",
    "                                              **kwargs\n",
    "                                             )\n",
    "    \n",
    "    return tensor_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409584b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saliency = Saliency(kitty)\n",
    "grads = saliency.attribute(input.cuda(), target=labels[ind].item())\n",
    "grads = np.transpose(grads.cpu().squeeze(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d807a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(kitty)\n",
    "attr_ig, delta = attribute_image_features(ig, input.cuda(), baselines=input.cuda() * 0, return_convergence_delta=True)\n",
    "attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "print('Approximation delta: ', abs(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b808669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(kitty)\n",
    "nt = NoiseTunnel(ig)\n",
    "attr_ig_nt = attribute_image_features(nt, input.cuda(), baselines=input.cuda() * 0, nt_type='smoothgrad_sq',\n",
    "                                      nt_samples=4, stdevs=0.2)\n",
    "attr_ig_nt = np.transpose(attr_ig_nt.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191afa93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = DeepLift(kitty)\n",
    "attr_dl = attribute_image_features(dl, input.cuda(), baselines=input.cuda() * 0)\n",
    "attr_dl = np.transpose(attr_dl.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497d4e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Original Image')\n",
    "print('Predicted:', classes[predicted[ind]], \n",
    "      ' Probability:', torch.max(F.softmax(outputs, 1)).item())\n",
    "\n",
    "original_image = np.transpose((images[ind].cpu().detach().numpy()), (1, 2, 0))\n",
    "\n",
    "_ = viz.visualize_image_attr(None, original_image, \n",
    "                      method=\"original_image\", title=\"Original Image\")\n",
    "\n",
    "_ = viz.visualize_image_attr(grads.numpy(), original_image, method=\"blended_heat_map\", sign=\"absolute_value\",\n",
    "                          show_colorbar=True, title=\"Overlayed Gradient Magnitudes\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_ig, original_image, method=\"blended_heat_map\",sign=\"all\",\n",
    "                          show_colorbar=True, title=\"Overlayed Integrated Gradients\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_ig_nt, original_image, method=\"blended_heat_map\", sign=\"absolute_value\", \n",
    "                             outlier_perc=10, show_colorbar=True, \n",
    "                             title=\"Overlayed Integrated Gradients \\n with SmoothGrad Squared\")\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_dl, original_image, method=\"blended_heat_map\",sign=\"all\",show_colorbar=True, \n",
    "                          title=\"Overlayed DeepLift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50adb635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
