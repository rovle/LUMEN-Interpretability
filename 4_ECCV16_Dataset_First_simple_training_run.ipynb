{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 - ECCV16 Dataset - First simple training run.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pdPlqMMbK2S"
      },
      "outputs": [],
      "source": [
        "# so I need folder structure like\n",
        "# train/nyc/...\n",
        "\n",
        "# test/nyc/...\n",
        "\n",
        "\n",
        "# 0069 — nyc\n",
        "# 0075 — las vegas\n",
        "# 0084 — firenca\n",
        "# 0093 — amsterdam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "OQpxyvM_e1uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import tarfile\n",
        "from math import ceil\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "f0xppm-zm_cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cities = {'0075' : 'las vegas', '0083' : 'firenca', '0093' : 'amsterdam'}"
      ],
      "metadata": {
        "id": "HaDtfn0_oFQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train\n",
        "!mkdir train/nyc\n",
        "!mkdir train/las\\ vegas\n",
        "!mkdir train/firenca\n",
        "!mkdir train/amsterdam\n",
        "\n",
        "!mkdir test\n",
        "!mkdir test/nyc\n",
        "!mkdir test/las\\ vegas\n",
        "!mkdir test/firenca\n",
        "!mkdir test/amsterdam"
      ],
      "metadata": {
        "id": "QXeM_QLhoU9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tars = ['0075', '0083', '0093']\n",
        "for tar_name in tqdm(tars):\n",
        "  subprocess.call(f'gsutil cp gs://eccv16/dataset_unaligned/{tar_name}.tar . ', shell=True, executable='/bin/bash')\n",
        "\n",
        "  tar = tarfile.open(f'{tar_name}.tar')\n",
        "  tar.extractall('.') # specify which folder to extract to\n",
        "  tar.close()\n",
        "\n",
        "  subprocess.call(f'rm -rf {tar_name}.tar', shell=True, executable='/bin/bash')\n"
      ],
      "metadata": {
        "id": "HBgYDM-immmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d2e9e5-011d-4f3a-ddc3-1f5624918087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [20:42<00:00, 414.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(x, y):\n",
        "  return (x[1] - y[1])**2 + (x[0] - y[0])**2\n",
        "\n",
        "def coors(filename):\n",
        "  with open(filename) as fp:\n",
        "    f = fp.read()\n",
        "    f = f.split(' ')\n",
        "    f = f[5:7]\n",
        "    f = [float(x) for x in f]\n",
        "  return tuple(f)\n",
        "\n",
        "def folders_to_coors(folder_name):\n",
        "  coor_set = list()\n",
        "  for file in os.listdir(folder_name):\n",
        "    if file[-3:] == 'txt':\n",
        "      try:\n",
        "        coords = coors(f'{folder_name}/{file}')\n",
        "      except UnicodeDecodeError:\n",
        "        continue\n",
        "      if coords not in coor_set:\n",
        "        coor_set.append(coords)\n",
        "  return coor_set"
      ],
      "metadata": {
        "id": "lrmruz64nBCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tar in tqdm(tars):\n",
        "  coordinates = folders_to_coors(tar)\n",
        "\n",
        "  train_set = []\n",
        "  test_set = []\n",
        "  chunks_size = ceil(0.1*len(coordinates))\n",
        "\n",
        "  i = 0\n",
        "  while coordinates != []:\n",
        "    print(len(coordinates))\n",
        "    anchor_point = min(coordinates, key=lambda x: x[0])\n",
        "    distances = [distance(x, anchor_point) for x in coordinates]\n",
        "    coors_and_dists = list(zip(coordinates, distances))\n",
        "    coors_and_dists = sorted(coors_and_dists, key=lambda x: x[1])\n",
        "    first_chunk = coors_and_dists[:chunks_size]\n",
        "    second_chunk = coors_and_dists[chunks_size:]\n",
        "    chunk = [x[0] for x in first_chunk]\n",
        "    coordinates = [x[0] for x in second_chunk]\n",
        "    if i % 2 == 0:\n",
        "      train_set += chunk\n",
        "    else:\n",
        "      test_set += chunk\n",
        "    i += 1\n",
        "\n",
        "  split = {'train' : [], 'test' : []}\n",
        "  for file in os.listdir(tar):\n",
        "    if file[-3:] == 'txt':\n",
        "      try:\n",
        "        coords = coors(f'{tar}/{file}')\n",
        "      except UnicodeDecodeError:\n",
        "        continue\n",
        "      if coords in train_set:\n",
        "        split['train'].append(file[:-4])\n",
        "      else:\n",
        "        split['test'].append(file[:-4])\n",
        "\n",
        "  split['train'] = [x + '.jpg' for x in split['train']]\n",
        "  split['test'] = [x + '.jpg' for x in split['test']]\n",
        "\n",
        "  for f in split['train']:\n",
        "    try:\n",
        "      shutil.move(os.path.join(tar, f), os.path.join('train', cities[tar]))\n",
        "    except FileNotFoundError:\n",
        "      continue  \n",
        "\n",
        "  for f in split['test']:\n",
        "    try:\n",
        "      shutil.move(os.path.join(tar, f), os.path.join('test', cities[tar]))\n",
        "    except FileNotFoundError:\n",
        "      continue  \n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMj3JQSonfh1",
        "outputId": "c16991c8-02fb-4ce2-edf1-bb386b3cf61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3416\n",
            "3074\n",
            "2732\n",
            "2390\n",
            "2048\n",
            "1706\n",
            "1364\n",
            "1022\n",
            "680\n",
            "338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [02:39<05:18, 159.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5677\n",
            "5109\n",
            "4541\n",
            "3973\n",
            "3405\n",
            "2837\n",
            "2269\n",
            "1701\n",
            "1133\n",
            "565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [06:01<03:04, 184.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6302\n",
            "5671\n",
            "5040\n",
            "4409\n",
            "3778\n",
            "3147\n",
            "2516\n",
            "1885\n",
            "1254\n",
            "623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [07:34<00:00, 151.50s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML part"
      ],
      "metadata": {
        "id": "DEbFG1jn7vD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p65FPFwwcAKN",
        "outputId": "f8e24e44-1829-4376-b352-50d4585d9900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    # you can add other transformations in this list\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root='train', transform=transform)\n",
        "test_data = torchvision.datasets.ImageFolder(root='test', transform=transform)"
      ],
      "metadata": {
        "id": "txndI6IfunWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "zHVBAaYfvOTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc3 = nn.Linear(394384, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "b7f60gCd9DZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "34YFZOJs-6PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydkwaZuX_CKw",
        "outputId": "800484de-2bb2-4303-995e-20f1065c817e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    50] loss: 1.361\n",
            "[1,   100] loss: 0.938\n",
            "[1,   150] loss: 0.861\n",
            "[1,   200] loss: 0.842\n",
            "[1,   250] loss: 0.834\n",
            "[1,   300] loss: 0.779\n",
            "[1,   350] loss: 0.805\n",
            "[1,   400] loss: 0.774\n",
            "[1,   450] loss: 0.749\n",
            "[1,   500] loss: 0.746\n",
            "[1,   550] loss: 0.703\n",
            "[1,   600] loss: 0.698\n",
            "[1,   650] loss: 0.674\n",
            "[1,   700] loss: 0.687\n",
            "[1,   750] loss: 0.659\n",
            "[1,   800] loss: 0.707\n",
            "[1,   850] loss: 0.628\n",
            "[1,   900] loss: 0.629\n",
            "[1,   950] loss: 0.637\n",
            "[1,  1000] loss: 0.612\n",
            "[1,  1050] loss: 0.590\n",
            "[1,  1100] loss: 0.603\n",
            "[1,  1150] loss: 0.580\n",
            "[1,  1200] loss: 0.569\n",
            "[1,  1250] loss: 0.556\n",
            "[1,  1300] loss: 0.562\n",
            "[1,  1350] loss: 0.551\n",
            "[1,  1400] loss: 0.544\n",
            "[1,  1450] loss: 0.565\n",
            "[1,  1500] loss: 0.521\n",
            "[1,  1550] loss: 0.534\n",
            "[1,  1600] loss: 0.511\n",
            "[1,  1650] loss: 0.531\n",
            "[1,  1700] loss: 0.502\n",
            "[1,  1750] loss: 0.525\n",
            "[1,  1800] loss: 0.474\n",
            "[1,  1850] loss: 0.516\n",
            "[1,  1900] loss: 0.483\n",
            "[1,  1950] loss: 0.486\n",
            "[1,  2000] loss: 0.479\n",
            "[1,  2050] loss: 0.471\n",
            "[1,  2100] loss: 0.453\n",
            "[1,  2150] loss: 0.483\n",
            "[1,  2200] loss: 0.466\n",
            "[1,  2250] loss: 0.446\n",
            "[1,  2300] loss: 0.474\n",
            "[1,  2350] loss: 0.493\n",
            "[1,  2400] loss: 0.441\n",
            "[1,  2450] loss: 0.414\n",
            "[1,  2500] loss: 0.430\n",
            "[1,  2550] loss: 0.451\n",
            "[1,  2600] loss: 0.430\n",
            "[1,  2650] loss: 0.454\n",
            "[1,  2700] loss: 0.429\n",
            "[1,  2750] loss: 0.428\n",
            "[1,  2800] loss: 0.393\n",
            "[1,  2850] loss: 0.416\n",
            "[1,  2900] loss: 0.404\n",
            "[1,  2950] loss: 0.429\n",
            "[1,  3000] loss: 0.387\n",
            "[1,  3050] loss: 0.387\n",
            "[1,  3100] loss: 0.406\n",
            "[1,  3150] loss: 0.385\n",
            "[1,  3200] loss: 0.379\n",
            "[1,  3250] loss: 0.391\n",
            "[1,  3300] loss: 0.378\n",
            "[1,  3350] loss: 0.391\n",
            "[1,  3400] loss: 0.374\n",
            "[1,  3450] loss: 0.356\n",
            "[2,    50] loss: 0.331\n",
            "[2,   100] loss: 0.297\n",
            "[2,   150] loss: 0.357\n",
            "[2,   200] loss: 0.314\n",
            "[2,   250] loss: 0.338\n",
            "[2,   300] loss: 0.329\n",
            "[2,   350] loss: 0.300\n",
            "[2,   400] loss: 0.284\n",
            "[2,   450] loss: 0.285\n",
            "[2,   500] loss: 0.288\n",
            "[2,   550] loss: 0.296\n",
            "[2,   600] loss: 0.306\n",
            "[2,   650] loss: 0.285\n",
            "[2,   700] loss: 0.279\n",
            "[2,   750] loss: 0.365\n",
            "[2,   800] loss: 0.294\n",
            "[2,   850] loss: 0.256\n",
            "[2,   900] loss: 0.300\n",
            "[2,   950] loss: 0.257\n",
            "[2,  1000] loss: 0.250\n",
            "[2,  1050] loss: 0.319\n",
            "[2,  1100] loss: 0.296\n",
            "[2,  1150] loss: 0.259\n",
            "[2,  1200] loss: 0.258\n",
            "[2,  1250] loss: 0.279\n",
            "[2,  1300] loss: 0.329\n",
            "[2,  1350] loss: 0.274\n",
            "[2,  1400] loss: 0.270\n",
            "[2,  1450] loss: 0.279\n",
            "[2,  1500] loss: 0.269\n",
            "[2,  1550] loss: 0.278\n",
            "[2,  1600] loss: 0.278\n",
            "[2,  1650] loss: 0.244\n",
            "[2,  1700] loss: 0.253\n",
            "[2,  1750] loss: 0.245\n",
            "[2,  1800] loss: 0.255\n",
            "[2,  1850] loss: 0.239\n",
            "[2,  1900] loss: 0.253\n",
            "[2,  1950] loss: 0.253\n",
            "[2,  2000] loss: 0.259\n",
            "[2,  2050] loss: 0.248\n",
            "[2,  2100] loss: 0.273\n",
            "[2,  2150] loss: 0.263\n",
            "[2,  2200] loss: 0.245\n",
            "[2,  2250] loss: 0.230\n",
            "[2,  2300] loss: 0.247\n",
            "[2,  2350] loss: 0.262\n",
            "[2,  2400] loss: 0.246\n",
            "[2,  2450] loss: 0.222\n",
            "[2,  2500] loss: 0.240\n",
            "[2,  2550] loss: 0.244\n",
            "[2,  2600] loss: 0.231\n",
            "[2,  2650] loss: 0.243\n",
            "[2,  2700] loss: 0.241\n",
            "[2,  2750] loss: 0.257\n",
            "[2,  2800] loss: 0.207\n",
            "[2,  2850] loss: 0.249\n",
            "[2,  2900] loss: 0.232\n",
            "[2,  2950] loss: 0.243\n",
            "[2,  3000] loss: 0.206\n",
            "[2,  3050] loss: 0.196\n",
            "[2,  3100] loss: 0.217\n",
            "[2,  3150] loss: 0.189\n",
            "[2,  3200] loss: 0.231\n",
            "[2,  3250] loss: 0.227\n",
            "[2,  3300] loss: 0.232\n",
            "[2,  3350] loss: 0.219\n",
            "[2,  3400] loss: 0.237\n",
            "[2,  3450] loss: 0.209\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './fourcities_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "MMg4iMVZ_HJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "rg-cSJBQ_NS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea252ced-510f-498d-b3aa-b439b9fecac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 83 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qtQIwSY_8mjH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}